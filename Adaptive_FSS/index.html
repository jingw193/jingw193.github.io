<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="Adaptive FSS">
  <meta property="og:title" content="Adaptive FSS"/>
  <meta property="og:description" content="Adaptive FSS: A Novel Few-Shot Segmentation Framework via Prototype Enhancement"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/video_t1.png" />
  <meta property="og:image:width" content="2412"/>
  <meta property="og:image:height" content="1394"/>


  <meta name="twitter:title" content="Adaptive FSS">
  <meta name="twitter:description" content="Adaptive FSS: A Novel Few-Shot Segmentation Framework via Prototype Enhancement">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/video_t1.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="Image-to-Video">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Adaptive FSS</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>

  
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Adaptive FSS: A Novel Few-Shot Segmentation Framework via Prototype Enhancement</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=Q9Np_KQAAAAJ&hl=en" target="_blank">Jing Wang</a><sup>1</sup>,&nbsp;&nbsp;</span>
              <span class="author-block">
                <a href="http://saee.ustb.edu.cn/quantijiaoshi/2015-05-12/69.html" target="_blank">Jiangyun Li</a><sup>1</sup>,&nbsp;&nbsp;</span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=TuEwcZ0AAAAJ&hl=en" target="_blank">Chen Chen</a><sup>2</sup>,&nbsp;&nbsp;</span>
              <span class="author-block">
                <a href="https://scholar.google.com.hk/citations?user=YG7_e9AAAAAJ&hl=zh-CN" target="_blank">Yisi Zhang</a><sup>1</sup>,&nbsp;&nbsp;</span>
              <span class="author-block">
                <a href="https://scholar.google.com.hk/citations?hl=zh-CN&pli=1&user=Lf4kCHoAAAAJ" target="_blank">Haoran Shen</a><sup>1</sup>,&nbsp;&nbsp;</span>
              <span class="author-block">
                <a href="https://www.researchgate.net/profile/Tianxiang-Zhang-2" target="_blank">Tianxiang Zhang</a><sup>1</sup>,&nbsp;&nbsp;</span>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block"><sup>1</sup>University of Science and Technology Beijing</span>
                    <span class="author-block"><sup>2</sup>University of Central Florida</span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Video link -->
                    <span class="link-block">
                      <a href="" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fab fa-youtube"></i>
                      </span>
                      <span>video</span>
                    </a>
                  </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/jingw193/Adaptive_FSS" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>



<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
             The Few-Shot Segmentation (FSS) aims to accomplish the novel class segmentation task with a few annotated images. Current FSS research based on meta-learning focuses on designing a complex interaction mechanism between the query and support feature. However, unlike humans who can rapidly learn new things from limited samples, the existing approach relies solely on fixed feature matching to tackle new tasks, lacking adaptability. In this paper, we propose a novel framework based on the adapter mechanism, namely Adaptive FSS, which can efficiently adapt the existing FSS model to the novel classes. In detail, we design the Prototype Adaptive Module (PAM), which utilizes accurate category information provided by the support set to derive class prototypes, enhancing class-specific information in the multi-stage representation. In addition, our approach is compatible with in diverse FSS methods with different backbones by simply inserting PAM between the layers of the encoder. Experiments demonstrate that our method effectively improves the performance of the FSS models (e.g., MSANet, HDMNet, FPTrans, and DCAMA) and achieves new state-of-the-art (SOTA) results (i.e., 72.4% and 79.1% mIoU on PASCAL-5<sup>i</sup> 1-shot and 5-shot settings, 52.7% and 60.0% mIoU on COCO-20<sup>i</sup> 1-shot and 5-shot settings).
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Method</h2>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/method.png" alt="MY ALT TEXT"/>
        <h2 class="content has-text-justified">
           The overall architecture of our proposed Adaptive FSS. Given a support set {I<SUB>s</SUB>, M<SUB>s</SUB>}, the image I<SUB>s</SUB> is fed into the encoder and generates feature F<SUB>s</SUB> (F<SUB>q</SUB>). In each PAM, with calculation between F<SUB>s</SUB> and mask M<SUB>s</SUB>, the temporary prototype P<SUB>t</SUB> is first obtained to select prototype P<SUB>i</SUB> and update the bank. After that, the corresponding class prototype P<SUB>i</SUB> and feature F<SUB>s</SUB> (F<SUB>q</SUB>) are combined to generate the class-specific feature F<SUB>s</SUB><sup>*</sup> (F<SUB>q</SUB><sup>*</sup>). Finally, F<SUB>s</SUB><sup>*</sup> (F<SUB>q</SUB><sup>*</sup>) is sent into the Learnable Adaptive Module, leading to the acquired \hat{F<SUB>s</SUB>} (\hat{F<SUB>q</SUB>}), which are injected into the encoder.
       </h2>
     </div>
    </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->

<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Quantitative Results</h2>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/Report_score.png" alt="MY ALT TEXT"/>
        <h2 class="content has-text-justified">
           To comprehensively evaluate our approach, we conduct experiments on four few-shot segmentation networks (MSANet, HDMANet, FPTrans, and DCAMA), which adopt three popular backbones (ResNet, Vision Transformer, and Swin Transformer) as shown in Table. It is worth emphasizing that we followed the test setting of DCAMA so that the performance of the other method is slightly different from that in the original paper. As expected, our method consistently improves the performance of existing FSS methods with different encoders on two benchmarks. 
       </h2>
     </div>
    </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->


  <!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Qualitative Results</h2>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/Vision_comparison.png" alt="MY ALT TEXT"/>
        <h2 class="content has-text-justified">
           This a visual comparison between the baseline and our Adaptive FSS on the PASCAL-5<sup>i</sup> as shown in figure. The FPTrans without finetuning is chosen as the baseline. Our method achieves high-quality segmentation due to adapting the model to new categories effectively. 
       </h2>
     </div>
    </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->



<!--BibTex citation -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{Jing2023Adaptive,
      title={Adaptive FSS: A Novel Few-Shot Segmentation Framework via Prototype Enhancement},
      author={Jing Wang},
      journal={arXiv preprint},
      website={https://jingw193.github.io/Adaptive_FSS/},
      year={2023}
}</code></pre>
  </div>
</section>


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<script>
bulmaCarousel.attach('#results-carousel11', {
    slidesToScroll: 1,
    slidesToShow: 2,
    infinite: true,
    autoplay: false,
});
bulmaCarousel.attach('#results-carousel22', {
    slidesToScroll: 1,
    slidesToShow: 2,
    infinite: true,
    autoplay: false,
});
bulmaCarousel.attach('#results-carousel33', {
    slidesToScroll: 1,
    slidesToShow: 2,
    infinite: true,
    autoplay: false,
});
</script>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
